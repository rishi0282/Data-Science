{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_diabetes()\n",
    "dataset\n",
    "x = dataset['data']\n",
    "x\n",
    "y = dataset['target']\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (353, 10)\n",
      "shape of y_train: (353,)\n",
      "shape of x_test: (89, 10)\n",
      "shape of y_test: (89,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size = 0.2,random_state=23)\n",
    "print(f\"shape of x_train: {x_train.shape}\")\n",
    "print(f\"shape of y_train: {y_train.shape}\")\n",
    "print(f\"shape of x_test: {x_test.shape}\")\n",
    "print(f\"shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.5282462062113"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### We are calculating the values of coeff_ and intercept_ in advance in order to check our method's accuracy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x_train,y_train)\n",
    "linreg.coef_\n",
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the Class GDregressor, which implements the batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Here, we want to implement the Multiple linear regression and using the (Batch) Gradient Descent algorithm to minimize the loss function.\n",
    "class GDregressor:\n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.coeff_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def fit(self,x_train,y_train):\n",
    "        # Whenever we start with the gradient descent we start with random values of each parameter and then update them at each iteration.\n",
    "        # So, In this case we are intializing them as 1.\n",
    "        \"\"\" This is a function which trains on Linear Regression for the given dataset and use Gradient Descent as its Loss Optimization technique.\\n Parameters: \\n x_train = input variables of the training dataset,\\n y_train = Output variables of the train dataset \"\"\"\n",
    "        self.coeff_ = np.ones(x_train.shape[1])\n",
    "        self.intercept_ = 0      # B0 \n",
    "        # print(f\"shape of coeff_ : {self.coeff_.shape}\")\n",
    "        for i in range (self.epochs):\n",
    "            # We calculated y_pred using the dot product method (m x n) . (n x 1)\n",
    "            y_pred = np.dot(x_train,self.coeff_) + self.intercept_\n",
    "            self.intercept_ = self.intercept_ - (self.lr * np.mean(y_train - y_pred) * (-2))\n",
    "            self.coeff_ = self.coeff_ - (self.lr * -2 * np.dot(y_train-y_pred,x_train)/x_train.shape[0])\n",
    "\n",
    "        print(self.intercept_)\n",
    "        # print(\"shape: \",self.coeff_.shape)\n",
    "        print(self.coeff_)\n",
    "\n",
    "    def predict(self,x_test):\n",
    "        y_pred = self.intercept_ + np.dot(x_test,self.coeff_)\n",
    "        # print(y_pred)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a SGDregression class which implements the stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDregressor:\n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs \n",
    "        self.coeff_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.coeff_ = np.ones(x_train.shape[1])\n",
    "        # print(self.coeff_)\n",
    "        self.intercept_ = 0 \n",
    "        for i in range(self.epochs):\n",
    "            for j in range (x_train.shape[0]):\n",
    "                \n",
    "                index = np.random.randint(0,x_train.shape[0])\n",
    "                \n",
    "                # print(index)\n",
    "                \n",
    "                y_pred = np.dot( x_train[index] , self.coeff_ ) + self.intercept_\n",
    "                self.intercept_ = self.intercept_ - (self.lr * (y_train[index]-y_pred) * (-2) )\n",
    "\n",
    "                self.coeff_ = self.coeff_ - (self.lr * (np.dot(y_train[index]-y_pred , x_train[index])) * (-2)   )\n",
    "\n",
    "        print(f\"coeff{i}: {self.coeff_}\")\n",
    "        print(f\"intercept{i}: {self.intercept_}\")\n",
    "\n",
    "    def predict(self,x_test):\n",
    "        y_pred = np.dot( x_test , self.coeff_ ) + self.intercept_\n",
    "        # print(f\"y_pred: {y_pred}\")\n",
    "        return y_pred\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeff49: [  37.22375102  -99.14401327  326.00824962  206.82662009   21.50641258\n",
      "  -13.93716078 -181.3944907   155.24105899  302.01017259  152.14617623]\n",
      "intercept49: 150.60785575218674\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "sgdr = SGDregressor(learning_rate,epochs)\n",
    "sgdr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[246.9842307  120.37740069 164.49404492  84.09578931 172.31005118\n",
      " 169.01893164 197.60055885 168.99874976 200.17500964 185.10871436\n",
      " 141.67798438 110.76564744 176.85933719  94.89165321 112.02181707\n",
      " 168.92786429 204.098973   184.4064809  130.99784073  86.75845037\n",
      " 267.53345088 119.19245967 161.06068083 179.02763911 153.66506435\n",
      " 159.73468379 171.29188279 163.57960802 244.80854196 110.58943756\n",
      " 158.97191863 208.27249615 161.95412235  97.04465916 213.24632579\n",
      " 232.57923422 136.77806329 152.9986874  157.05441144 142.62872297\n",
      " 163.32597995 239.02503529  85.47491979 138.71337678  90.84249354\n",
      " 228.35447757 176.43345562  58.6273449  180.67804919 104.02530754\n",
      " 171.88672546 124.70839181 233.02941474 173.46351477 204.69310061\n",
      "  98.74955499 240.81500844 103.36694967 172.58464171 229.92711071\n",
      " 195.49111834 166.60926811 141.77855486 179.77874223 182.86137273\n",
      " 123.87094846 146.45862161 151.39381545 216.45382818 207.62496862\n",
      " 100.95674844  97.41219749 227.00451684 122.52914372 153.37820823\n",
      " 145.64052993 216.54143419 183.6333392   89.46971462 159.20701619\n",
      " 213.22463817 103.87446496 187.3501852  222.67868183 155.78425838\n",
      " 176.25925591 173.56089574 162.39003402 207.42469399]\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgdr.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4222812256832609\n",
      "n: 89, k: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34821471615547384"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(r2)\n",
    "n = y_test.shape[0]\n",
    "k = x_train.shape[1]\n",
    "print(f\"n: {n}, k: {k}\")\n",
    "r2_adj = 1 - ((1-r2)*(n-1)/(n-1-k))\n",
    "r2_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.33863650255188\n",
      "[  22.30266882 -156.55821276  399.40748585  247.86619955   -6.86221083\n",
      "  -54.49030682 -202.0416576   157.04656456  358.30390391  158.15622196]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.4\n",
    "epochs = 700\n",
    "gdr = GDregressor(learning_rate,epochs)\n",
    "gdr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([267.84219409, 119.7610977 , 157.07595419,  73.33891885,\n",
       "       179.94251238, 179.66020439, 202.13290259, 164.05284597,\n",
       "       204.81365421, 195.20055112, 136.73977332, 105.11224134,\n",
       "       176.92289573,  89.65630287, 109.24293412, 175.51123579,\n",
       "       214.57899914, 186.7011811 , 134.59858718,  82.44528326,\n",
       "       281.17779784, 123.23694874, 161.31332461, 178.89762063,\n",
       "       144.27369584, 159.75686063, 170.21874731, 162.34003998,\n",
       "       263.96577788, 105.95720825, 160.75886159, 222.16469375,\n",
       "       160.27365792,  93.77971317, 204.03280983, 236.38323701,\n",
       "       135.09637585, 150.67923067, 166.1859409 , 135.29396509,\n",
       "       161.38095846, 256.26855917,  79.38262343, 141.6118568 ,\n",
       "        84.451348  , 239.812494  , 179.05348419,  51.16549213,\n",
       "       182.82618803,  99.73333335, 168.08970647, 124.07849797,\n",
       "       241.25610838, 176.36111848, 214.43589879,  97.59803012,\n",
       "       254.83843743,  96.24190023, 176.36993435, 236.20451106,\n",
       "       195.70936129, 174.91229065, 136.38896832, 181.56280597,\n",
       "       184.67992872, 122.47802347, 149.26324202, 144.71699228,\n",
       "       222.56737614, 208.38239347,  94.05833874,  93.63579627,\n",
       "       239.74223282, 124.04956057, 161.44530805, 150.09663038,\n",
       "       220.00805755, 184.17036918,  90.93604211, 156.34006988,\n",
       "       221.41247238, 102.284231  , 204.03899884, 242.61690584,\n",
       "       150.73115454, 174.89261496, 177.00462017, 159.88965952,\n",
       "       223.66619559])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gdr.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4222812256832609\n",
      "n: 89, k: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34821471615547384"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(r2)\n",
    "n = y_test.shape[0]\n",
    "k = x_train.shape[1]\n",
    "print(f\"n: {n}, k: {k}\")\n",
    "r2_adj = 1 - ((1-r2)*(n-1)/(n-1-k))\n",
    "r2_adj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
