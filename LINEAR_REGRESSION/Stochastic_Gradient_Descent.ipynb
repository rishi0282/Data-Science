{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_diabetes()\n",
    "dataset\n",
    "x = dataset['data']\n",
    "x\n",
    "y = dataset['target']\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (353, 10)\n",
      "shape of y_train: (353,)\n",
      "shape of x_test: (89, 10)\n",
      "shape of y_test: (89,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size = 0.2,random_state=23)\n",
    "print(f\"shape of x_train: {x_train.shape}\")\n",
    "print(f\"shape of y_train: {y_train.shape}\")\n",
    "print(f\"shape of x_test: {x_test.shape}\")\n",
    "print(f\"shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.5282462062113"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### We are calculating the values of coeff_ and intercept_ in advance in order to check our method's accuracy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x_train,y_train)\n",
    "linreg.coef_\n",
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the Class GDregressor, which implements the batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Here, we want to implement the Multiple linear regression and using the (Batch) Gradient Descent algorithm to minimize the loss function.\n",
    "class GDregressor:\n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.coeff_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def fit(self,x_train,y_train):\n",
    "        # Whenever we start with the gradient descent we start with random values of each parameter and then update them at each iteration.\n",
    "        # So, In this case we are intializing them as 1.\n",
    "        \"\"\" This is a function which trains on Linear Regression for the given dataset and use Gradient Descent as its Loss Optimization technique.\\n Parameters: \\n x_train = input variables of the training dataset,\\n y_train = Output variables of the train dataset \"\"\"\n",
    "        self.coeff_ = np.ones(x_train.shape[1])\n",
    "        self.intercept_ = 0      # B0 \n",
    "        # print(f\"shape of coeff_ : {self.coeff_.shape}\")\n",
    "        for i in range (self.epochs):\n",
    "            # We calculated y_pred using the dot product method (m x n) . (n x 1)\n",
    "            y_pred = np.dot(x_train,self.coeff_) + self.intercept_\n",
    "            self.intercept_ = self.intercept_ - (self.lr * np.mean(y_train - y_pred) * (-2))\n",
    "            self.coeff_ = self.coeff_ - (self.lr * -2 * np.dot(y_train-y_pred,x_train)/x_train.shape[0])\n",
    "\n",
    "        print(self.intercept_)\n",
    "        # print(\"shape: \",self.coeff_.shape)\n",
    "        print(self.coeff_)\n",
    "\n",
    "    def predict(self,x_test):\n",
    "        y_pred = self.intercept_ + np.dot(x_test,self.coeff_)\n",
    "        # print(y_pred)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a SGDregression class which implements the stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDregressor:\n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs \n",
    "        self.coeff_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def learning_rate(self,t):\n",
    "        t0,t1 = 5,50\n",
    "        return t0/(t+t1)\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.coeff_ = np.ones(x_train.shape[1])\n",
    "        # print(self.coeff_)\n",
    "        self.intercept_ = 0 \n",
    "\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range (x_train.shape[0]):\n",
    "                # learning schedules\n",
    "                self.lr = self.learning_rate(i*x.shape[0]+j)\n",
    "                index = np.random.randint(0,x_train.shape[0])\n",
    "                \n",
    "                # print(index)\n",
    "                \n",
    "                y_pred = np.dot( x_train[index] , self.coeff_ ) + self.intercept_\n",
    "                self.intercept_ = self.intercept_ - (self.lr * (y_train[index]-y_pred) * (-2) )\n",
    "\n",
    "                self.coeff_ = self.coeff_ - (self.lr * (np.dot(y_train[index]-y_pred , x_train[index])) * (-2)   )\n",
    "\n",
    "        print(f\"coeff{i}: {self.coeff_}\")\n",
    "        print(f\"intercept{i}: {self.intercept_}\")\n",
    "\n",
    "    def predict(self,x_test):\n",
    "        y_pred = np.dot( x_test , self.coeff_ ) + self.intercept_\n",
    "        # print(f\"y_pred: {y_pred}\")\n",
    "        return y_pred\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeff119: [ 25.36005963  -5.01900319 106.68624521  71.92899791  28.94104952\n",
      "  25.19346486 -68.9397219   70.1431161   93.68724245  63.49546188]\n",
      "intercept119: 149.02174101419283\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.4\n",
    "epochs = 120\n",
    "sgdr = SGDregressor(learning_rate,epochs)\n",
    "sgdr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179.68616242 136.10807083 160.65359255 126.62223567 154.59210566\n",
      " 151.51445906 167.39883411 160.87184254 169.4132562  158.42456902\n",
      " 148.48627923 135.04844995 161.37336452 127.49451412 133.1738259\n",
      " 153.86256503 166.82212561 163.37522961 138.05101715 122.6896918\n",
      " 193.75062989 132.21341042 153.91154664 162.68041896 157.17623758\n",
      " 154.17124216 159.36858702 156.12749685 180.19735122 133.75965874\n",
      " 151.86613618 166.05396126 156.26551749 126.4597359  185.33383691\n",
      " 184.5205408  143.71001712 151.67569775 147.13745788 151.0042956\n",
      " 156.18334962 177.53800637 123.62014597 141.92423026 126.03902487\n",
      " 178.59451793 159.16306789 111.98654907 162.28734509 131.06410303\n",
      " 161.84713776 138.18805399 181.1386909  157.55616422 167.59557321\n",
      " 126.84352356 181.09744711 132.1753039  157.94316845 182.46644047\n",
      " 169.70317693 151.26897824 149.4796068  161.53277791 163.17083078\n",
      " 137.67864687 146.04480741 154.14123253 175.4889207  174.51725499\n",
      " 130.96519372 127.26712125 177.21823653 135.21263135 145.90740989\n",
      " 144.08298327 177.99347885 164.14554186 119.85531789 155.21223175\n",
      " 173.11210342 129.70970902 156.34903329 169.71313788 154.82154769\n",
      " 162.56819457 156.2643019  156.35466123 164.58378224]\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgdr.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1892394360598687\n",
      "n: 89, k: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0852957740162622"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(r2)\n",
    "n = y_test.shape[0]\n",
    "k = x_train.shape[1]\n",
    "print(f\"n: {n}, k: {k}\")\n",
    "r2_adj = 1 - ((1-r2)*(n-1)/(n-1-k))\n",
    "r2_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.33863650255188\n",
      "[  22.30266882 -156.55821276  399.40748585  247.86619955   -6.86221083\n",
      "  -54.49030682 -202.0416576   157.04656456  358.30390391  158.15622196]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.4\n",
    "epochs = 700\n",
    "gdr = GDregressor(learning_rate,epochs)\n",
    "gdr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([267.84219409, 119.7610977 , 157.07595419,  73.33891885,\n",
       "       179.94251238, 179.66020439, 202.13290259, 164.05284597,\n",
       "       204.81365421, 195.20055112, 136.73977332, 105.11224134,\n",
       "       176.92289573,  89.65630287, 109.24293412, 175.51123579,\n",
       "       214.57899914, 186.7011811 , 134.59858718,  82.44528326,\n",
       "       281.17779784, 123.23694874, 161.31332461, 178.89762063,\n",
       "       144.27369584, 159.75686063, 170.21874731, 162.34003998,\n",
       "       263.96577788, 105.95720825, 160.75886159, 222.16469375,\n",
       "       160.27365792,  93.77971317, 204.03280983, 236.38323701,\n",
       "       135.09637585, 150.67923067, 166.1859409 , 135.29396509,\n",
       "       161.38095846, 256.26855917,  79.38262343, 141.6118568 ,\n",
       "        84.451348  , 239.812494  , 179.05348419,  51.16549213,\n",
       "       182.82618803,  99.73333335, 168.08970647, 124.07849797,\n",
       "       241.25610838, 176.36111848, 214.43589879,  97.59803012,\n",
       "       254.83843743,  96.24190023, 176.36993435, 236.20451106,\n",
       "       195.70936129, 174.91229065, 136.38896832, 181.56280597,\n",
       "       184.67992872, 122.47802347, 149.26324202, 144.71699228,\n",
       "       222.56737614, 208.38239347,  94.05833874,  93.63579627,\n",
       "       239.74223282, 124.04956057, 161.44530805, 150.09663038,\n",
       "       220.00805755, 184.17036918,  90.93604211, 156.34006988,\n",
       "       221.41247238, 102.284231  , 204.03899884, 242.61690584,\n",
       "       150.73115454, 174.89261496, 177.00462017, 159.88965952,\n",
       "       223.66619559])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gdr.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4222812256832609\n",
      "n: 89, k: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34821471615547384"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(r2)\n",
    "n = y_test.shape[0]\n",
    "k = x_train.shape[1]\n",
    "print(f\"n: {n}, k: {k}\")\n",
    "r2_adj = 1 - ((1-r2)*(n-1)/(n-1-k))\n",
    "r2_adj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
